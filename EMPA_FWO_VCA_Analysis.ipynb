# =============================
# EMPA-FWO-VCA Algorithm Analysis
# =============================

# Import required libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
from mmfw_rfe import MMFW_RFE  # Import the MMFW-RFE algorithm

# =============================
# Step 1: Load and Explore Dataset
# =============================
df = pd.read_csv("dataset.csv")  # Replace with actual dataset path
print("Dataset Head:\n", df.head())
print("\nDataset Info:")
df.info()

# Check for missing values
print("\nMissing Values:\n", df.isnull().sum())

# =============================
# Step 2: Preprocessing
# =============================
# Separate features (X) and target variable (y)
X = df.drop(columns=["target"])  # Assuming 'target' is the class label
y = df["target"]

# Split dataset into training and testing sets (80-20 split)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# =============================
# Step 3: Feature Selection using MMFW-RFE
# =============================
mmfw_rfe = MMFW_RFE(n_features_to_select=10)  # Select top 10 features
X_train_selected = mmfw_rfe.fit_transform(X_train, y_train)
X_test_selected = mmfw_rfe.transform(X_test)

# Get selected features
PA = mmfw_rfe.selected_features
FSOI = mmfw_rfe.optimization_index  # Assuming MMFW_RFE provides an optimization index

print("\nSelected Prime Attributes (PA):", PA)
print("\nFeature Subset Optimization Index (FSOI):", FSOI)

# =============================
# Step 4: Train Weak Classifiers
# =============================
dt = DecisionTreeClassifier(random_state=42)
nb = GaussianNB()
svm = SVC(probability=True, random_state=42)

# Train classifiers using selected prime attributes
dt.fit(X_train_selected, y_train)
nb.fit(X_train_selected, y_train)
svm.fit(X_train_selected, y_train)

# =============================
# Step 5: Predictions Using Weak Classifiers
# =============================
predictions = []

for i in range(X_test_selected.shape[0]):
    dt_pred = dt.predict([X_test_selected[i]])[0]
    nb_pred = nb.predict([X_test_selected[i]])[0]
    svm_pred = svm.predict([X_test_selected[i]])[0]
    
    # Store predictions for analysis
    predictions.append([dt_pred, nb_pred, svm_pred])

# =============================
# Step 6: Voting Classifier Ensemble
# =============================
# Majority Voting Mechanism
ensemble_predictions = []

for i in range(len(predictions)):
    final_pred = max(set(predictions[i]), key=predictions[i].count)  # Majority vote
    ensemble_predictions.append(final_pred)

# =============================
# Step 7: Evaluate Performance
# =============================
accuracy = accuracy_score(y_test, ensemble_predictions)
fscore = f1_score(y_test, ensemble_predictions, average="weighted")

print("\nAccuracy of Voting Classifier:", accuracy)
print("F-score of Voting Classifier:", fscore)
print("\nClassification Report:\n", classification_report(y_test, ensemble_predictions))

# =============================
# Step 8: Confusion Matrix Visualization
# =============================
conf_matrix = confusion_matrix(y_test, ensemble_predictions)

plt.figure(figsize=(6, 6))
sns.heatmap(conf_matrix, annot=True, cmap="Blues", fmt="d", xticklabels=np.unique(y), yticklabels=np.unique(y))
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix for EMPA-FWO-VCA")
plt.show()

# =============================
# Step 9: Feature Importance Visualization
# =============================
feature_importance = pd.Series(dt.feature_importances_, index=PA).sort_values(ascending=False)

plt.figure(figsize=(8, 5))
feature_importance.plot(kind="bar", color="teal")
plt.xlabel("Feature Names")
plt.ylabel("Importance Score")
plt.title("Feature Importance of Selected Attributes")
plt.show()
